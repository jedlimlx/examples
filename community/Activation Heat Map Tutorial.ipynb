{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Activation Heat Maps.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"JZ3tLauVdY75","colab_type":"text"},"source":["# **Activation Heat Maps in tf.Keras**\n","\n","Deep learning models are black-box in nature. From a business-oriented perspective, it is important to understand how a model is making a particular prediction, more specifically -- what parts of the given input signal are contributing to a model's prediction. This is helpful for all business stakeholders.\n","\n","The field of computer vision has progressed rapidly with modern deep learning cavalry. Today, it's absolutely possible to train a high-quality image classification model within a very less amount of time. But the model interpretability part still remains a major challenge. An effective deep learning practitioner should have the right tools to explain his/her deep learning models.\n","\n","In this tutorial, you will explore how to visualize activation heat maps in tf.Keras.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rNljIA4ieC2A","colab_type":"text"},"source":["# **Loading Cifar10 Dataset**\n","\n","Firstly, you have to load our dataset.\n","For the purposes of this tutorial, you will use the Cifar10 Dataset.\n","The data is normalised before being fed into the model."]},{"cell_type":"code","metadata":{"id":"EjQ2zrDldUmp","colab_type":"code","colab":{}},"source":["%tensorflow_version 2.x\n","import numpy as np\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.utils import to_categorical\n","\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data() # Loading Data\n","test_images = x_test  # Set aside original validation images\n","\n","x_train = np.array(x_train).astype(\"float32\") / 255 # Normalisation\n","x_test = np.array(x_test).astype(\"float32\") / 255\n","\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ht3j8lJZhjt5","colab_type":"text"},"source":["# **Constructing the Model**\n","\n","A CNN with Dropouts for this image classification task.\n","The dropouts are used to help avoid overfitting.\n","The model is compiled with RMSProp Optimizer and Categorical Crossentropy loss.\n"]},{"cell_type":"code","metadata":{"id":"Hkzk5nKLe5NB","colab_type":"code","colab":{}},"source":["from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.losses import categorical_crossentropy\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import *\n","\n","inputs = Input(shape=(32, 32, 3)) # Image Shape for Cifar-10\n","x = (Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))(inputs)\n","\n","x = (Conv2D(128, (3, 3), activation='relu', padding=\"same\"))(x)\n","x = (MaxPooling2D(pool_size=(2, 2)))(x)\n","x = (Dropout(0.25))(x)  # Dropouts prevent overfitting\n","\n","x = (Conv2D(64, (3, 3), activation='relu', padding=\"same\"))(x)\n","x = (MaxPooling2D(pool_size=(2, 2)))(x)\n","x = (Dropout(0.25))(x)\n","\n","x = (Conv2D(64, (3, 3), activation='relu', padding=\"same\"))(x)\n","x = (Conv2D(32, (3, 3), activation='relu', padding=\"same\"))(x)\n","x = (Dropout(0.25))(x)\n","\n","x = (Conv2D(32, (3, 3), activation='relu', padding=\"same\"))(x)\n","x = (Conv2D(16, (3, 3), activation='relu', padding=\"same\"))(x)\n","x = (MaxPooling2D(pool_size=(2, 2)))(x)\n","x = (BatchNormalization())(x)\n","\n","x = (Conv2D(32, (3, 3), activation='relu', padding=\"same\"))(x)\n","x = (Conv2D(16, (3, 3), activation='relu', padding=\"same\"))(x)\n","x = (MaxPooling2D(pool_size=(2, 2)))(x)\n","x = (BatchNormalization())(x)\n","x = (Flatten())(x)\n","\n","x = (Dense(128, activation='relu'))(x)\n","x = (Dense(64, activation='relu'))(x)\n","x = (Dropout(0.5))(x)\n","x = (Dense(len(y_test[0]), activation='softmax'))(x)\n","\n","model = Model(inputs=inputs, outputs=x)\n","model.compile(loss=categorical_crossentropy, optimizer=RMSprop(), metrics=['accuracy']) # Compile Model\n","\n","model.fit(x_train, y_train, batch_size=512, epochs=150, verbose=1, validation_data=(x_test, y_test)) # Training\n","\n","loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n","\n","print('Test Loss:', loss)\n","print('Test Accuracy:', accuracy)\n","\n","model.save_weights(\"model.h5\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9yX3iQ8Gq4_d","colab_type":"text"},"source":["# **Activation Heat Maps**\n","\n","Now, with the trained model, you will visualize some activation heat maps. You will use Gradient Based Class Activation Maps (Grad-CAM)\n","\n","Class activation maps are a simple technique to get the discriminative image regions used by a CNN to identify a specific class in the image. In other words, a gradient based class activation map (Grad-CAM) lets you see which regions in the image were relevant to this class. This also shows how deep learning networks already have some kind of a built in attention mechanism.\n","\n","Such heat maps can be useful in debugging and understanding what leads a model to make a prediction.\n","\n","In such a heat map, the bluer the region, the more that region mattered to the model.\n"]},{"cell_type":"code","metadata":{"id":"U4PVgEcoq4d2","colab_type":"code","colab":{}},"source":["import cv2\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import random\n","\n","LAYER_NAME = 'conv2d_8' # Layer Name of Last Conv2D Layer\n","img_num = 4102\n","\n","def get_heat_map(model, LAYER_NAME, img_data, original_image, label):\n","    # Create a graph that outputs target convolution and output\n","    grad_model = Model([model.inputs], [model.get_layer(LAYER_NAME).output, model.output])\n","\n","    # Get the score for target class\n","    with tf.GradientTape() as tape:\n","        conv_outputs, predictions = grad_model(np.array([img_data]))\n","        for i in range(10):\n","            if label[i] == 1:\n","                index = i\n","                break\n","\n","        loss = predictions[:, index]\n","\n","    # Extract filters and gradients\n","    output = conv_outputs[0]\n","    grads = tape.gradient(loss, conv_outputs)[0]\n","\n","    # Average gradients spatially\n","    weights = tf.reduce_mean(grads, axis=(0, 1))\n","\n","    # Build a ponderated map of filters according to gradients importance\n","    cam = np.ones(output.shape[0:2], dtype=np.float32)\n","\n","    for index, w in enumerate(weights):\n","        cam += w * output[:, :, index]\n","\n","    img = original_image.astype('uint8')\n","\n","    # Heatmap visualization\n","    cam = cv2.resize(cam.numpy(), (np.shape(img)[0], np.shape(img)[1]))\n","    cam = np.maximum(cam, 0)\n","    heatmap = (cam - cam.min()) / (cam.max() - cam.min())\n","\n","    cam = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n","\n","    output_image = cv2.addWeighted(img, 0.6, cam, 0.4, 0)\n","    return output_image\n","\n","\n","output_image = get_heat_map(model, LAYER_NAME, x_test[img_num], test_images[img_num], y_test[img_num])\n","plt.subplot(1, 2, 1)\n","plt.imshow(test_images[img_num])\n","\n","plt.subplot(1, 2, 2)\n","plt.imshow(output_image)\n","\n","labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \n","          \"frog\", \"horse\", \"ship\", \"truck\"]\n","\n","pred = model.predict(np.array([x_test[img_num]]))\n","max_index = 0\n","max_num = 0\n","for i in range(10):\n","    if pred[0][i] > max_num:\n","        max_num = pred[0][i]\n","        max_index = i\n","\n","for i in range(10):\n","    if y_test[img_num][i] == 1:\n","        index = i\n","        break\n","\n","print(\"The Model thinks this is a \" + labels[max_index])\n","print(\"It is actually a \" + labels[index])\n","print(\"Image Number:\", img_num)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1H3SHQOai_1i","colab_type":"text"},"source":["# **Interpreting the Results**\n","\n","As you can see, the model is able to pick up on some of the defining features of a plane such as its wings.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gPsjOMAxmCNG","colab_type":"text"},"source":["# **Summary**\n","\n","In this tutorial, you have learnt how to use tf.keras to create gradient based class activation maps (Grad-CAM) which are useful for debugging and explaining the predictions of deep learning models. Thank you!\n","\n","References: https://www.sicara.ai/blog/2019-08-28-interpretability-deep-learning-tensorflow\n"]}]}
